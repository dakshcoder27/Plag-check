{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "1359d9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "from difflib import SequenceMatcher\n",
    "import tokenize\n",
    "from io import BytesIO\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz # Often used with pydot for rendering, though not directly used for plotting here.\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "import tempfile\n",
    "import re\n",
    "\n",
    "# Use a non-interactive backend for Matplotlib, which is good for generating images without a display.\n",
    "# This is crucial in environments where a GUI might not be available (e.g., servers, automated scripts).\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "6b1a994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_codes_from_folder(folder_path):\n",
    "    code_files = [f for f in os.listdir(folder_path) if f.endswith(\".c\")]\n",
    "    codes = {}\n",
    "    for file in code_files:\n",
    "        with open(os.path.join(folder_path, file), 'r') as f:\n",
    "            codes[file] = f.read()\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1fc17988",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_str = \"kadane algo in c\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "663e4f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "code=load_codes_from_folder(folder_path_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "41068e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'s1.c': '#include <stdio.h>\\n\\nint max(int a, int b) {\\n    return (a > b) ? a : b;\\n}\\n\\nint maxSubArray(int* nums, int numsSize) {\\n    int maxSum = nums[0];\\n    int currentSum = nums[0];\\n\\n    for (int i = 1; i < numsSize; ++i) {\\n        currentSum = max(nums[i], currentSum + nums[i]);\\n        maxSum = max(maxSum, currentSum);\\n    }\\n\\n    return maxSum;\\n}\\n\\nint main() {\\n    int nums[] = {-2, 1, -3, 4, -1, 2, 1, -5, 4};\\n    int size = sizeof(nums) / sizeof(nums[0]);\\n\\n    int result = maxSubArray(nums, size);\\n    printf(\"Max Subarray Sum: %d\\\\n\", result);\\n\\n    return 0;\\n}\\n',\n",
       " 's2.c': '#include <stdio.h>\\n#include <limits.h>  // For INT_MIN\\n\\nint maxSubArray(int* nums, int numsSize) {\\n    int max_sum = INT_MIN;  // Equivalent to float(\\'-inf\\')\\n    int current_sum = 0;\\n\\n    for (int i = 0; i < numsSize; ++i) {\\n        current_sum += nums[i];\\n\\n        if (current_sum > max_sum) {\\n            max_sum = current_sum;\\n        }\\n\\n        if (current_sum < 0) {\\n            current_sum = 0;\\n        }\\n    }\\n\\n    return max_sum;\\n}\\n\\nint main() {\\n    int nums[] = {-2, 1, -3, 4, -1, 2, 1, -5, 4};\\n    int size = sizeof(nums) / sizeof(nums[0]);\\n\\n    int result = maxSubArray(nums, size);\\n    printf(\"Max Subarray Sum: %d\\\\n\", result);\\n\\n    return 0;\\n}\\n',\n",
       " 's3.c': '#include <stdio.h>\\n#include <limits.h>\\n\\nint max(int a, int b) {\\n    return (a > b) ? a : b;\\n}\\n\\nint maxSubArray(int* nums, int numsSize) {\\n    int currSum = nums[0];\\n    int maxSum = nums[0];\\n\\n    for (int i = 1; i < numsSize; ++i) {\\n        currSum = max(nums[i], currSum + nums[i]);  // extend or start new\\n        maxSum = max(maxSum, currSum);\\n    }\\n\\n    return maxSum;\\n}\\n\\nint main() {\\n    int nums[] = {-2, 1, -3, 4, -1, 2, 1, -5, 4};\\n    int size = sizeof(nums) / sizeof(nums[0]);\\n\\n    int result = maxSubArray(nums, size);\\n    printf(\"Max Subarray Sum: %d\\\\n\", result);\\n\\n    return 0;\\n}\\n',\n",
       " 's4.c': '#include <stdio.h>\\n#include <stdlib.h>\\n\\nint max(int a, int b) {\\n    return (a > b) ? a : b;\\n}\\n\\nint maxSubArray(int* nums, int numsSize) {\\n    // Create a DP array (like Python\\'s arr[])\\n    int* arr = (int*)malloc(numsSize * sizeof(int));\\n    arr[0] = nums[0];\\n\\n    int maxSum = arr[0];\\n\\n    for (int i = 1; i < numsSize; ++i) {\\n        arr[i] = max(nums[i], arr[i - 1] + nums[i]);\\n\\n        if (arr[i] > maxSum) {\\n            maxSum = arr[i];\\n        }\\n    }\\n\\n    free(arr);  // Always free dynamically allocated memory\\n    return maxSum;\\n}\\n\\nint main() {\\n    int nums[] = {-2, 1, -3, 4, -1, 2, 1, -5, 4};\\n    int size = sizeof(nums) / sizeof(nums[0]);\\n\\n    int result = maxSubArray(nums, size);\\n    printf(\"Max Subarray Sum: %d\\\\n\", result);\\n\\n    return 0;\\n}\\n',\n",
       " 's5.c': '#include <stdio.h>\\n#include <limits.h>  // For INT_MIN\\n\\nint max(int a, int b) {\\n    return (a > b) ? a : b;\\n}\\n\\nint maxSubArray(int* nums, int numsSize) {\\n    int maximumSum = INT_MIN;\\n    int currSumSubarray = 0;\\n\\n    for (int i = 0; i < numsSize; ++i) {\\n        currSumSubarray += nums[i];\\n        maximumSum = max(maximumSum, currSumSubarray);\\n        currSumSubarray = max(currSumSubarray, 0);\\n    }\\n\\n    return maximumSum;\\n}\\n\\nint main() {\\n    int nums[] = {-2, 1, -3, 4, -1, 2, 1, -5, 4};\\n    int size = sizeof(nums) / sizeof(nums[0]);\\n\\n    int result = maxSubArray(nums, size);\\n    printf(\"Max Subarray Sum: %d\\\\n\", result);\\n\\n    return 0;\\n}\\n'}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "90f005ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=token_similarity(code['s1.c'], code['s2.c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "bff89b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tokenize\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "af9c8bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token frequency chart saved to: output_plots\\code1_token_frequency.png\n",
      "Token frequency chart saved to: output_plots\\code2_token_frequency.png\n",
      "\n",
      "Similarity between code1 and code2: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sctokenizer import CTokenizer, TokenType\n",
    "# Assuming you have the c_tokenizer function defined as in our last conversation.\n",
    "# If not, make sure to include it.\n",
    "\n",
    "# --- Re-define c_tokenizer (from our previous successful attempt) ---\n",
    "def c_tokenizer(c_code_string: str) -> list:\n",
    "    \"\"\"\n",
    "    Tokenizes a C code string and categorizes tokens into a simplified list.\n",
    "    \"\"\"\n",
    "    tokenizer = CTokenizer()\n",
    "    tokens = tokenizer.tokenize(c_code_string)\n",
    "    processed_tokens = []\n",
    "    for token in tokens:\n",
    "        if token.token_type == TokenType.COMMENT_SYMBOL:\n",
    "            continue\n",
    "        if token.token_type == TokenType.IDENTIFIER:\n",
    "            processed_tokens.append(\"IDENTIFIER\")\n",
    "        elif token.token_type == TokenType.OPERATOR:\n",
    "            processed_tokens.append(\"OPERATOR\")\n",
    "        elif token.token_type == TokenType.CONSTANT:\n",
    "            processed_tokens.append('NUMBER')\n",
    "        elif token.token_type == TokenType.STRING:\n",
    "            processed_tokens.append('STRING')\n",
    "        elif token.token_type == TokenType.KEYWORD:\n",
    "            processed_tokens.append(\"KEYWORD\")\n",
    "        elif token.token_type == TokenType.SPECIAL_SYMBOL:\n",
    "            processed_tokens.append(\"SPECIAL_SYMBOL\")\n",
    "        elif token.token_type == TokenType.OTHER:\n",
    "            if token.token_value.startswith('#'):\n",
    "                processed_tokens.append(\"PREPROCESSOR\")\n",
    "            else:\n",
    "                processed_tokens.append(\"OTHER\")\n",
    "    return processed_tokens\n",
    "\n",
    "# --- Define tokenize_code to use c_tokenizer (as discussed previously) ---\n",
    "def tokenize_code(code_string):\n",
    "    \"\"\"Tokenizes C code string using c_tokenizer.\"\"\"\n",
    "    return c_tokenizer(code_string)\n",
    "\n",
    "# --- Define token_similarity (as discussed previously) ---\n",
    "def token_similarity(code1, code2):\n",
    "    \"\"\"Calculates Jaccard similarity between two code snippets based on their tokens.\"\"\"\n",
    "    tokens1, tokens2 = tokenize_code(code1), tokenize_code(code2)\n",
    "    set1 = set(tokens1)\n",
    "    set2 = set(tokens2)\n",
    "    intersection = len(set1.intersection(set2))\n",
    "    union = len(set1.union(set2))\n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return intersection / union\n",
    "\n",
    "# --- Updated visualize_tokens function ---\n",
    "def visualize_tokens(code: str, filename: str, output_folder: str = \"output\") -> str:\n",
    "    \"\"\"\n",
    "    Tokenizes code, calculates token frequencies, and saves a bar chart\n",
    "    to a specified output folder.\n",
    "\n",
    "    Args:\n",
    "        code: The source code string to visualize.\n",
    "        filename: The desired name for the output image file (e.g., \"token_freq.png\").\n",
    "        output_folder: The directory where the image will be saved.\n",
    "                       Defaults to \"output\".\n",
    "\n",
    "    Returns:\n",
    "        The full path to the saved image file.\n",
    "    \"\"\"\n",
    "    tokens = tokenize_code(code)\n",
    "    token_counts = {token: tokens.count(token) for token in set(tokens)}\n",
    "\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(token_counts.keys(), token_counts.values(), color='skyblue')\n",
    "    plt.title(f\"Token Frequency for '{filename}'\") # Add filename to title for clarity\n",
    "    plt.xlabel(\"Token Type\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45, ha='right') # Rotate for long token names\n",
    "\n",
    "    plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
    "    filepath = os.path.join(output_folder, filename) # Join folder and filename\n",
    "    plt.savefig(filepath)\n",
    "    plt.close() # Close the plot to free up memory\n",
    "\n",
    "    print(f\"Token frequency chart saved to: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "# --- Example Usage ---\n",
    "\n",
    "# C Code Snippets for demonstration\n",
    "c_code_example1 = \"\"\"\n",
    "/* My first C program */\n",
    "#include <stdlib.h>\n",
    "\n",
    "void calculate_sum(int a, int b) {\n",
    "    int sum = a + b;\n",
    "    // Done calculation\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "c_code_example2 = \"\"\"\n",
    "// Another C program\n",
    "#include <stdlib.h>\n",
    "\n",
    "void calculate_sum(int a, int b) {\n",
    "    int sum = a + b;\n",
    "    // Done calculation\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# 1. Visualize tokens for c_code_example1\n",
    "output_dir = \"output_plots\" # Define your output folder name\n",
    "visualize_tokens(c_code_example1, \"code1_token_frequency.png\", output_dir)\n",
    "\n",
    "# 2. Visualize tokens for c_code_example2\n",
    "visualize_tokens(c_code_example2, \"code2_token_frequency.png\", output_dir)\n",
    "\n",
    "# 3. Calculate similarity between them\n",
    "similarity = token_similarity(c_code_example1, c_code_example2)\n",
    "print(f\"\\nSimilarity between code1 and code2: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "2f6dd398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycparser import c_parser\n",
    "from pycparser.c_ast import Node, ID, Constant, FuncCall, Decl, For, While\n",
    "from itertools import zip_longest\n",
    "from pycparser import c_parser\n",
    "import re\n",
    "# --- Your earlier code for cleaning C code ---\n",
    "def clean_c_code(code, add_stdio_stubs=True):\n",
    "    code = re.sub(r'^\\s*#include.*$', '', code, flags=re.MULTILINE)\n",
    "    code = re.sub(r'//.*', '', code)\n",
    "    code = re.sub(r'/\\*.*?\\*/', '', code, flags=re.DOTALL)\n",
    "    stub_funcs = \"\"\n",
    "    if add_stdio_stubs:\n",
    "        if re.search(r'\\bprintf\\b', code):\n",
    "            stub_funcs += \"void printf(char*, ...);\\n\"\n",
    "        if re.search(r'\\bscanf\\b', code):\n",
    "            stub_funcs += \"void scanf(char*, ...);\\n\"\n",
    "    return stub_funcs + code\n",
    "\n",
    "# --- The pycparser parser object ---\n",
    "parser = c_parser.CParser()\n",
    "\n",
    "parser = c_parser.CParser()\n",
    "\n",
    "weights = {\n",
    "    'match': 1.0,\n",
    "    'insert_delete': -0.7,\n",
    "    'update': -0.5,\n",
    "    'soft_update': -0.2,\n",
    "    'match_For': 1.5,\n",
    "    'update_For': -1.0,\n",
    "}\n",
    "\n",
    "def compare_ast_nodes(node1, node2, weights):\n",
    "    if node1 is None and node2 is None:\n",
    "        return (0, 0)\n",
    "    if node1 is None or node2 is None:\n",
    "        return (weights[\"insert_delete\"], 1)\n",
    "    if type(node1) != type(node2):\n",
    "        type_name = \"update_\" + type(node1).__name__\n",
    "        return (weights.get(type_name, weights[\"update\"]), 1)\n",
    "\n",
    "    score = weights.get(\"match_\" + type(node1).__name__, weights[\"match\"])\n",
    "    max_score = 1\n",
    "\n",
    "    for attr in node1.attr_names:\n",
    "        if attr in (\"name\", \"value\", \"op\"):\n",
    "            if getattr(node1, attr, None) != getattr(node2, attr, None):\n",
    "                score += weights[\"soft_update\"]\n",
    "\n",
    "    children1 = list(node1.children())\n",
    "    children2 = list(node2.children())\n",
    "\n",
    "    from itertools import zip_longest\n",
    "    for pair1, pair2 in zip_longest(children1, children2):\n",
    "        c1 = pair1[1] if pair1 is not None else None\n",
    "        c2 = pair2[1] if pair2 is not None else None\n",
    "        s, m = compare_ast_nodes(c1, c2, weights)\n",
    "        score += s\n",
    "        max_score += m\n",
    "\n",
    "    return score, max_score\n",
    "\n",
    "\n",
    "def semantic_similarity(ast1, ast2):\n",
    "    score, max_score = compare_ast_nodes(ast1, ast2, weights)\n",
    "    return max(min(score / max_score, 1.0), 0.0) if max_score > 0 else 0.0  # Clamp safely\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "66990fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Semantic similarity = 0.6143\n"
     ]
    }
   ],
   "source": [
    "ast1 = parser.parse(clean_c_code(\"\"\"int main() {\n",
    "    int sum = 0;\n",
    "    for (int i = 1; i <= 10; i++) {\n",
    "        sum = sum + i;\n",
    "    }\n",
    "    return sum;\n",
    "}\n",
    "\"\"\"))\n",
    "ast2 = parser.parse(clean_c_code(\"\"\"int main() {\n",
    "    int total = 0;\n",
    "    int number = 1;\n",
    "    while (number <= 10) {\n",
    "        total += number;\n",
    "        number++;\n",
    "    }\n",
    "    return total;\n",
    "}\n",
    "\"\"\"))\n",
    "\n",
    "sim = semantic_similarity(ast1, ast2)\n",
    "print(f\"✓ Semantic similarity = {sim:.4f}\")  # Should be in [0.0, 1.0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b09976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8469a90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
