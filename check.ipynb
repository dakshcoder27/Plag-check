{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79474644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "from difflib import SequenceMatcher\n",
    "import tokenize\n",
    "from io import BytesIO\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import graphviz\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")  # Use non-interactive backend for Flask\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67bba2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: graphviz in c:\\users\\deepak jain\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.21)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8991f548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ast_similarity(code1, code2):\n",
    "    try:\n",
    "        tree1, tree2 = ast.parse(code1), ast.parse(code2)\n",
    "    except SyntaxError:\n",
    "        return 0.0\n",
    "    nodes1 = [type(node).__name__ for node in ast.walk(tree1)]\n",
    "    nodes2 = [type(node).__name__ for node in ast.walk(tree2)]\n",
    "    return SequenceMatcher(None, nodes1, nodes2).ratio()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6866579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_code(code):\n",
    "    tokens = []\n",
    "    g = tokenize.tokenize(BytesIO(code.encode('utf-8')).readline)\n",
    "    for token in g:\n",
    "        if token.type == tokenize.NAME:\n",
    "            tokens.append('IDENTIFIER')\n",
    "        elif token.type == tokenize.OP:\n",
    "            tokens.append(token.string)\n",
    "        elif token.type == tokenize.NUMBER:\n",
    "            tokens.append('NUMBER')\n",
    "        elif token.type == tokenize.STRING:\n",
    "            tokens.append('STRING')\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca009dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_similarity(code1, code2):\n",
    "    tokens1, tokens2 = tokenize_code(code1), tokenize_code(code2)\n",
    "    set1 = set(tokens1)\n",
    "    set2 = set(tokens2)\n",
    "    intersection = set1.intersection(set2)\n",
    "    union = set1.union(set2)\n",
    "    return len(intersection) / len(union) if len(union) != 0 else 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa54869e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from networkx.algorithms.similarity import graph_edit_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14e5d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ControlFlowGraphBuilder(ast.NodeVisitor):\n",
    "    def __init__(self):\n",
    "        self.cfg = nx.DiGraph()\n",
    "        self.current_node = None\n",
    "        self.node_count = 0\n",
    "\n",
    "    def add_node(self, label):\n",
    "        node_id = self.node_count\n",
    "        self.cfg.add_node(node_id, label=label)\n",
    "        if self.current_node is not None:\n",
    "            self.cfg.add_edge(self.current_node, node_id)\n",
    "        self.current_node = node_id\n",
    "        self.node_count += 1\n",
    "\n",
    "    def visit_FunctionDef(self, node):\n",
    "        self.add_node(f\"FunctionDef: {node.name}\")\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def visit_If(self, node):\n",
    "        self.add_node(\"If\")\n",
    "        self.generic_visit(node)\n",
    "    def visit_For(self, node):\n",
    "        self.add_node(\"For\")\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def visit_While(self, node):\n",
    "        self.add_node(\"While\")\n",
    "        self.generic_visit(node)\n",
    "\n",
    "    def visit_Return(self, node):\n",
    "        self.add_node(\"Return\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "322a370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_control_flow_graph(code):\n",
    "    tree = ast.parse(code)\n",
    "    builder = ControlFlowGraphBuilder()\n",
    "    builder.visit(tree)\n",
    "    return builder.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fafe3456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_flow_similarity(code1, code2):\n",
    "    cfg1 = build_control_flow_graph(code1)\n",
    "    cfg2 = build_control_flow_graph(code2)\n",
    "    ged = graph_edit_distance(cfg1, cfg2)\n",
    "    normalized_score = 1 / (1 + ged) if ged is not None else 0\n",
    "    return normalized_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15c6be7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_similarity(ast_sim, token_sim, control_flow_sim, weights=(0.4, 0.4, 0.2)):\n",
    "    return (weights[0] * ast_sim) + (weights[1] * token_sim) + (weights[2] * control_flow_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c171cbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_codes_from_folder(folder_path):\n",
    "    code_files = [f for f in os.listdir(folder_path) if f.endswith(\".py\")]\n",
    "    codes = {}\n",
    "    for file in code_files:\n",
    "        with open(os.path.join(folder_path, file), 'r') as f:\n",
    "            codes[file] = f.read()\n",
    "    return codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c24d7472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pairwise_similarities(codes):\n",
    "    similarity_threshold = 0.7\n",
    "    files = list(codes.keys())\n",
    "    similarities = []\n",
    "    for i, file1 in enumerate(files):\n",
    "        for j, file2 in enumerate(files):\n",
    "            if i < j:\n",
    "                ast_sim = ast_similarity(codes[file1], codes[file2])\n",
    "                token_sim = token_similarity(codes[file1], codes[file2])\n",
    "                control_flow_sim = control_flow_similarity(codes[file1], codes[file2])\n",
    "                overall_sim = calculate_weighted_similarity(ast_sim, token_sim, control_flow_sim)\n",
    "                if overall_sim > similarity_threshold:\n",
    "                    similarities.append((file1, file2, overall_sim))\n",
    "    return similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d628d4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_codes(similarities, codes, eps=0.5, min_samples=2):\n",
    "    files = list(codes.keys())\n",
    "    n = len(files)\n",
    "    similarity_matrix = np.zeros((n, n))\n",
    "    for (file1, file2, sim) in similarities:\n",
    "        i, j = files.index(file1), files.index(file2)\n",
    "        similarity_matrix[i][j] = similarity_matrix[j][i] = sim\n",
    "    clustering = DBSCAN(eps=eps, min_samples=min_samples, metric=\"precomputed\")\n",
    "    labels = clustering.fit_predict(1 - similarity_matrix)\n",
    "    clusters = {}\n",
    "    for idx, label in enumerate(labels):\n",
    "        if label not in clusters:\n",
    "            clusters[label] = []\n",
    "        clusters[label].append(files[idx])\n",
    "    # save_similarity_to_csv(similarity_matrix, files, output_path=\"similarity_matrix.csv\")\n",
    "    return clusters, similarity_matrix, files\n",
    "\n",
    "def save_similarity_to_csv(similarity_matrix, files, output_path=\"similarity_matrix.csv\"):\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(similarity_matrix, index=files, columns=files).round(2)\n",
    "    df.to_csv(output_path)\n",
    "    print(f\"CSV file saved to {output_path}\")\n",
    "\n",
    "def set_cell_font(cell, bold=False, font_name='Calibri', font_size=10):\n",
    "    paragraphs = cell.paragraphs\n",
    "    for paragraph in paragraphs:\n",
    "        run = paragraph.runs[0] if paragraph.runs else paragraph.add_run()\n",
    "        run.font.name = font_name\n",
    "        run.font.size = Pt(font_size)\n",
    "        run.bold = bold\n",
    "\n",
    "def set_cell_width(cell, width_in_inches=1.5):\n",
    "    tc = cell._tc\n",
    "    tcPr = tc.get_or_add_tcPr()\n",
    "    tcW = OxmlElement('w:tcW')\n",
    "    tcW.set(qn('w:type'), 'dxa')\n",
    "    tcW.set(qn('w:w'), str(int(width_in_inches * 1440)))  # 1 inch = 1440 twips\n",
    "    tcPr.append(tcW)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8546a95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_similarity_matrix(similarity_matrix, files, output_dir):\n",
    "    # Ensure diagonal values are 1\n",
    "    np.fill_diagonal(similarity_matrix, 1)\n",
    "    \n",
    "\n",
    "    # Set figure size and create the heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(\n",
    "        similarity_matrix, \n",
    "        annot=True, \n",
    "        fmt=\".2f\", \n",
    "        xticklabels=files, \n",
    "        yticklabels=files, \n",
    "        cmap=\"YlGnBu\", \n",
    "        cbar=True, \n",
    "        square=True  # Ensures cells are square-shaped\n",
    "    )\n",
    "    \n",
    "    # Rotate labels for better readability\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    \n",
    "    # Add a title and adjust layout\n",
    "    plt.title(\"Code Similarity Heatmap\", fontsize=16, pad=20)\n",
    "    plt.tight_layout()  # Automatically adjust layout to prevent cutoff\n",
    "\n",
    "    # Save the heatmap\n",
    "    filename = os.path.join(output_dir, \"similarity_matrix.png\")\n",
    "    plt.savefig(filename, dpi=300)  # High resolution for better quality\n",
    "    plt.close()\n",
    "    \n",
    "    return filename\n",
    "\n",
    "def visualize_ast(code, filename):\n",
    "    try:\n",
    "        tree = ast.parse(code)\n",
    "        graph = nx.DiGraph()  # Directed Graph to maintain tree structure\n",
    "\n",
    "        def add_nodes_edges(node, parent=None):\n",
    "            node_id = str(id(node))\n",
    "            graph.add_node(node_id, label=type(node).__name__)\n",
    "\n",
    "            if parent:\n",
    "                graph.add_edge(parent, node_id)\n",
    "\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                add_nodes_edges(child, node_id)\n",
    "\n",
    "        add_nodes_edges(tree)\n",
    "\n",
    "        # Extract labels for nodes\n",
    "        labels = nx.get_node_attributes(graph, 'label')\n",
    "\n",
    "        # Use `spring_layout` for a simple tree-like structure\n",
    "        pos = nx.spring_layout(graph, seed=42)\n",
    "\n",
    "        # Plot the tree\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        nx.draw(graph, pos, labels=labels, with_labels=True, node_color=\"lightblue\",\n",
    "                edge_color=\"gray\", node_size=3000, font_size=10, font_weight=\"bold\")\n",
    "\n",
    "        # Save the file\n",
    "        plt.savefig(filename, format='png', dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        return filename\n",
    "\n",
    "    except SyntaxError:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "856fa33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tokens(code, filename):\n",
    "    tokens = tokenize_code(code)\n",
    "    token_counts = {token: tokens.count(token) for token in set(tokens)}\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.bar(token_counts.keys(), token_counts.values(), color='skyblue')\n",
    "    plt.title(\"Token Frequency\")\n",
    "    plt.xlabel(\"Token Type\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    filepath = f\"{filename}.png\"\n",
    "    plt.savefig(filepath)\n",
    "    plt.close()\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89a6e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_control_flow(code, filename):\n",
    "    try:\n",
    "        tree = ast.parse(code)\n",
    "        graph = nx.DiGraph()\n",
    "\n",
    "        def add_nodes_edges(node, parent=None):\n",
    "            node_id = str(id(node))\n",
    "            graph.add_node(node_id, label=type(node).__name__)\n",
    "            if parent:\n",
    "                graph.add_edge(str(id(parent)), node_id)\n",
    "            for child in ast.iter_child_nodes(node):\n",
    "                add_nodes_edges(child, node)\n",
    "\n",
    "        add_nodes_edges(tree)\n",
    "\n",
    "        pos = nx.spring_layout(graph, k=0.5)  # Adjust k to increase spacing\n",
    "        labels = nx.get_node_attributes(graph, 'label')\n",
    "        node_sizes = [1000 if labels[node] == 'FunctionDef' else 300 for node in graph]\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        nx.draw(graph, pos, labels=labels, with_labels=True, node_size=node_sizes, node_color=\"lightblue\", font_size=10)\n",
    "        \n",
    "        filepath = f\"{filename}.png\"\n",
    "        plt.savefig(filepath)\n",
    "        plt.close()\n",
    "        return filepath\n",
    "    except SyntaxError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def visualize_similarity_graph(similarity_matrix, files, output_dir):\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    G = nx.Graph()\n",
    "\n",
    "    for file in files:\n",
    "        G.add_node(file)\n",
    "\n",
    "    similarity_values = []\n",
    "    edges = []\n",
    "    for i in range(len(files)):\n",
    "        for j in range(i + 1, len(files)):\n",
    "            similarity_score = similarity_matrix[i][j]\n",
    "            if similarity_score > 0:\n",
    "                G.add_edge(files[i], files[j], weight=similarity_score)\n",
    "                similarity_values.append(similarity_score)\n",
    "                edges.append((files[i], files[j]))\n",
    "\n",
    "    min_sim = min(similarity_values) if similarity_values else 0\n",
    "    max_sim = max(similarity_values) if similarity_values else 1\n",
    "    edge_colors = [\n",
    "        (similarity_matrix[i][j] - min_sim) / (max_sim - min_sim)\n",
    "        for i in range(len(files)) for j in range(i + 1, len(files))\n",
    "        if similarity_matrix[i][j] > 0\n",
    "    ]\n",
    "\n",
    "    pos = nx.spring_layout(G, seed=42, k=1.5, iterations=50)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    nx.draw_networkx_nodes(G, pos, ax=ax, node_size=700, node_color=\"lightblue\", edgecolors=\"black\")\n",
    "    nx.draw_networkx_edges(G, pos, ax=ax, edgelist=edges, edge_color=edge_colors, edge_cmap=plt.cm.viridis, width=2)\n",
    "    nx.draw_networkx_labels(G, pos, ax=ax, font_size=10, font_weight=\"bold\")\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=plt.cm.viridis, norm=plt.Normalize(vmin=min_sim, vmax=max_sim))\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax)\n",
    "    cbar.set_label(\"Similarity Score\")\n",
    "\n",
    "    # Save the graph in the output directory\n",
    "    graph_path = output_dir / \"similarity_graph.png\"\n",
    "    plt.savefig(graph_path, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Similarity graph saved at {graph_path}\")\n",
    "\n",
    "def generate_output_files(similarity_matrix, output_dir):\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for filename, code in codes.items():\n",
    "        ast_file = visualize_ast(code, output_dir / f\"{filename}_ast.png\")\n",
    "        token_file = visualize_tokens(code, output_dir / f\"{filename}_tokens.png\")\n",
    "        cfg_file = visualize_control_flow(code, output_dir / f\"{filename}_cfg.png\")\n",
    "\n",
    "        print(f\"Generated visualizations for {filename}:\")\n",
    "        print(f\"  AST: {ast_file}\")\n",
    "        print(f\"  Tokens: {token_file}\")\n",
    "        print(f\"  Control Flow: {cfg_file}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e037854c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Code Clusters based on AST/Token/Control Flow Similarity:\n",
      "🟡 Outliers: ['s1.py', 's2.py', 's3.py', 's4.py', 's5.py']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepak jain\\AppData\\Local\\Temp\\ipykernel_32208\\288412647.py:53: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (similarity_matrix[i][j] - min_sim) / (max_sim - min_sim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity graph saved at output_files\\similarity_graph.png\n",
      "✅ Visualizations for s1.py:\n",
      "  AST: output_files\\s1_ast.png\n",
      "  Tokens: output_files\\s1_tokens.png.png\n",
      "  Control Flow: output_files\\s1_cfg.png.png\n",
      "✅ Visualizations for s2.py:\n",
      "  AST: output_files\\s2_ast.png\n",
      "  Tokens: output_files\\s2_tokens.png.png\n",
      "  Control Flow: output_files\\s2_cfg.png.png\n",
      "✅ Visualizations for s3.py:\n",
      "  AST: output_files\\s3_ast.png\n",
      "  Tokens: output_files\\s3_tokens.png.png\n",
      "  Control Flow: output_files\\s3_cfg.png.png\n",
      "✅ Visualizations for s4.py:\n",
      "  AST: output_files\\s4_ast.png\n",
      "  Tokens: output_files\\s4_tokens.png.png\n",
      "  Control Flow: output_files\\s4_cfg.png.png\n",
      "✅ Visualizations for s5.py:\n",
      "  AST: output_files\\s5_ast.png\n",
      "  Tokens: output_files\\s5_tokens.png.png\n",
      "  Control Flow: output_files\\s5_cfg.png.png\n",
      "\n",
      "✅ All outputs saved in: C:\\Users\\deepak jain\\Desktop\\Plag-check\\output_files\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Define your input folder and output directory\n",
    "    folder_path = \"buy_and_sell_stock\"  # Your source code folder\n",
    "    output_dir = Path(\"output_files\")  # Output directory for visualizations\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Load all code files\n",
    "    codes = load_codes_from_folder(folder_path)\n",
    "\n",
    "    # Compute pairwise similarities\n",
    "    similarities = calculate_pairwise_similarities(codes)\n",
    "\n",
    "    # Cluster based on similarity\n",
    "    clusters, similarity_matrix, files = cluster_codes(similarities, codes)\n",
    "\n",
    "    # Print clustering result\n",
    "    print(\"\\n🔍 Code Clusters based on AST/Token/Control Flow Similarity:\")\n",
    "    for cluster_id, cluster_files in clusters.items():\n",
    "        if cluster_id == -1:\n",
    "            print(\"🟡 Outliers:\", cluster_files)\n",
    "        else:\n",
    "            print(f\"🟢 Cluster {cluster_id}: {cluster_files}\")\n",
    "\n",
    "    #  Visualize Similarity Heatmap and Graph\n",
    "    visualize_similarity_matrix(similarity_matrix, files, output_dir)\n",
    "    visualize_similarity_graph(similarity_matrix, files, output_dir)\n",
    "\n",
    "    #  Generate per-code AST, Token, CFG visualizations\n",
    "    generate_output_files(output_dir, codes)\n",
    "\n",
    "    print(f\"\\n✅ All outputs saved in: {output_dir.resolve()}\")\n",
    "\n",
    "\n",
    "# Make sure generate_output_files takes codes\n",
    "def generate_output_files( output_dir, codes):\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for filename, code in codes.items():\n",
    "        base_name = Path(filename).stem  # Strip \".py\" if present\n",
    "        ast_file = visualize_ast(code, output_dir / f\"{base_name}_ast.png\")\n",
    "        token_file = visualize_tokens(code, output_dir / f\"{base_name}_tokens.png\")\n",
    "        cfg_file = visualize_control_flow(code, output_dir / f\"{base_name}_cfg.png\")\n",
    "\n",
    "        print(f\"✅ Visualizations for {filename}:\")\n",
    "        print(f\"  AST: {ast_file}\")\n",
    "        print(f\"  Tokens: {token_file}\")\n",
    "        print(f\"  Control Flow: {cfg_file}\")\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1f5d879",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"buy_and_sell_stock\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9ebafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = load_codes_from_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353c5529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1.py\n",
      "<ast.Module object at 0x000001B1579CF050>\n",
      "s2.py\n",
      "<ast.Module object at 0x000001B157A05B50>\n",
      "s3.py\n",
      "<ast.Module object at 0x000001B1579CF050>\n",
      "s4.py\n",
      "<ast.Module object at 0x000001B1563DE4D0>\n",
      "s5.py\n",
      "<ast.Module object at 0x000001B1579CF050>\n"
     ]
    }
   ],
   "source": [
    "for a in codes:\n",
    "    print(a)   \n",
    "    print(ast.parse(codes[a]))\n",
    "    nodes1 = [type(node).__name__ for node in ast.walk(ast.parse(codes[a]))]\n",
    "    print(nodes1)\n",
    "\n",
    "#so i can say that they are in a kind of dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "058b431c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ast\u001b[38;5;241m.\u001b[39mparse(codes[\u001b[43ms2\u001b[49m\u001b[38;5;241m.\u001b[39mpy])\n",
      "\u001b[1;31mNameError\u001b[0m: name 's2' is not defined"
     ]
    }
   ],
   "source": [
    "ast.parse(codes[s2.py])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbeeb13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
